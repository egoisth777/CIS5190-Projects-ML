{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5638b0d1",
   "metadata": {
    "id": "5638b0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exifread in e:\\repos\\course-projects\\cis5190-projects-ml\\cis5190-fin-project\\.conda\\lib\\site-packages (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install exifread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yT4UQMosNN02",
   "metadata": {
    "id": "yT4UQMosNN02"
   },
   "source": [
    "# Extracting GPS Information from Images\n",
    "\n",
    "(You will need to modify this script based on how your dataset is stored in order to execute the code.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7QcjgXtAQB5Q",
   "metadata": {
    "id": "7QcjgXtAQB5Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# train_or_test_or_validation could be either train, test, or validation.\n",
    "train_or_test_or_validation = \"validation\" # it could also be test or validation\n",
    "PATH_TO_YOUR_DATA_FOLDER = \"../../../../DataSet/519Photos\"\n",
    "directory_path = f\"{PATH_TO_YOUR_DATA_FOLDER}/{train_or_test_or_validation}\"\n",
    "output_csv = \"metadata.csv\"\n",
    "output_csv = os.path.join(directory_path, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1713e4e-a848-42e9-b8d8-d1273f1b9689",
   "metadata": {
    "id": "e1713e4e-a848-42e9-b8d8-d1273f1b9689"
   },
   "outputs": [],
   "source": [
    "import exifread, csv\n",
    "\n",
    "def get_exif_data(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        tags = exifread.process_file(image_file)\n",
    "    return tags\n",
    "\n",
    "def export_exif_to_json(exif_data, output_file):\n",
    "    # Convert tags to a serializable format\n",
    "    exif_data_serializable = {str(tag): str(value) for tag, value in exif_data.items()}\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(exif_data_serializable, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fb378d",
   "metadata": {
    "id": "80fb378d"
   },
   "outputs": [],
   "source": [
    "# Function to convert GPS coordinates in degrees, minutes, and seconds to decimal degrees\n",
    "def convert_to_decimal_degrees(value):\n",
    "    d, m, s = value.values\n",
    "    return d.num / d.den + (m.num / m.den) / 60 + (s.num / s.den) / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yaoJPVKrNq9N",
   "metadata": {
    "id": "yaoJPVKrNq9N"
   },
   "source": [
    "### You will need to create subfolders in {PATH_TO_YOUR_DATA_FOLDER} for each split (train/test/validation) or just (train/test). Next, place the corresponding images into each split after randomly shuffling them. Then, create a metadata.csv file for each split and place it in the corresponding directory. Note that the current code only works for jpeg images. If the exported images are in some other format, convert them to .jpg before running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c347d",
   "metadata": {
    "id": "be3c347d"
   },
   "outputs": [],
   "source": [
    "with open(output_csv, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['file_name', 'Latitude', 'Longitude']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "            exif_data = get_exif_data(os.path.join(directory_path, filename))\n",
    "            if exif_data:\n",
    "                gps_latitude = exif_data.get('GPS GPSLatitude', None)\n",
    "                gps_latitude_ref = exif_data.get('GPS GPSLatitudeRef', None)\n",
    "                gps_longitude = exif_data.get('GPS GPSLongitude', None)\n",
    "                gps_longitude_ref = exif_data.get('GPS GPSLongitudeRef', None)\n",
    "                if gps_latitude and gps_longitude:\n",
    "                    # Convert latitude and longitude to decimal degrees\n",
    "                    latitude = convert_to_decimal_degrees(gps_latitude)\n",
    "                    longitude = convert_to_decimal_degrees(gps_longitude)\n",
    "\n",
    "                    # Adjust for N/S and E/W reference\n",
    "                    if gps_latitude_ref.values[0] == 'S':\n",
    "                        latitude = -latitude\n",
    "                    if gps_longitude_ref.values[0] == 'W':\n",
    "                        longitude = -longitude\n",
    "\n",
    "                    # Write the data to the CSV file\n",
    "                    writer.writerow({'file_name': filename, 'Latitude': latitude, 'Longitude': longitude})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WEkVLwUcQ7PV",
   "metadata": {
    "id": "WEkVLwUcQ7PV"
   },
   "source": [
    "# Uploading and Reading a Dataset on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xtmhkAUSRBxp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtmhkAUSRBxp",
    "outputId": "cab82646-49d6-431e-bb91-a5fee48296f6"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dkkEth2_Ui18",
   "metadata": {
    "id": "dkkEth2_Ui18"
   },
   "source": [
    "### You need to ensure that your Hugging Face token has both read and write access to your repository and Hugging Face organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ZHlkuzFUhDX",
   "metadata": {
    "id": "5ZHlkuzFUhDX"
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b82545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the CSV\n",
    "import pandas as pd\n",
    "train_metadata = pd.read_csv(f'{PATH_TO_YOUR_DATA_FOLDER}/train/metadata.csv')\n",
    "validation_metadata = pd.read_csv(f'{PATH_TO_YOUR_DATA_FOLDER}/validation/metadata.csv')\n",
    "test_metadata = pd.read_csv(f'{PATH_TO_YOUR_DATA_FOLDER}/test/metadata.csv')\n",
    "\n",
    "print(train_metadata)\n",
    "print(validation_metadata)\n",
    "print(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quS-mt_9RIpd",
   "metadata": {
    "id": "quS-mt_9RIpd"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=PATH_TO_YOUR_DATA_FOLDER)\n",
    "dataset.push_to_hub(\"cis519/dataset_v2\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o9Cyq_g9Wf8h",
   "metadata": {
    "id": "o9Cyq_g9Wf8h"
   },
   "outputs": [],
   "source": [
    "### After uploading, you can access your data using this code\n",
    "dataset_test = load_dataset(\"{YOUR ORGANIZATION NAME}/{DATASET NAME}\", split=\"{YOUR SPLIT}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

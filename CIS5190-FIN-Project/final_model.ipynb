{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StbjPeFjroEl"
   },
   "source": [
    "# **Prerequisites**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0bKqI_UZNso"
   },
   "source": [
    "## Installing dependencies\n",
    "\n",
    "Please make a copy of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBj9R3VCAYkv",
    "outputId": "d5e0a1e5-278a-4aa9-849a-a94a2967f850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing the dependencies\n",
    "%pip install geopy > delete.txt\n",
    "%pip install datasets > delete.txt\n",
    "%pip install torch torchvision datasets > delete.txt\n",
    "%pip install huggingface_hub > delete.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete.txt has been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"delete.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)  # Remove the file\n",
    "    print(f\"{file_path} has been deleted.\")\n",
    "else:\n",
    "    print(f\"{file_path} does not exist. No action taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_d8uxEsCZTBc"
   },
   "source": [
    "## Huggingface login\n",
    "You will require your personal token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5vOXHY5Ifv2",
    "outputId": "9e444124-5b1f-41b8-9a13-9151d23bf9cd"
   },
   "outputs": [],
   "source": [
    "! huggingface-cli login "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv_nG_P8W7Bn"
   },
   "source": [
    "# **Dataset handling**\n",
    "This section is in charge of\n",
    "- Donwloading Data from Hugging Face to local runtime\n",
    "- Custom Dataset Class\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GokzmxKZupF"
   },
   "source": [
    "## Downloading the train and test dataset from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i80m6Kr6I_8A"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image\n",
    "\n",
    "# Loading the training, validation, and test dataset\n",
    "dataset_train = load_dataset(\"cis519/train\", split=\"train\")\n",
    "dataset_val = load_dataset(\"cis519/train\", split=\"validation\")\n",
    "dataset_test = load_dataset(\"cis519/train\", split=\"test\")\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfrpS0h-sH9V"
   },
   "source": [
    "## Custom Dataset Class\n",
    "- Below section creates a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMA_KggnsRDN"
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GPSImageDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None, lat_mean=None, lat_std=None, lon_mean=None, lon_std=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "        # Compute mean and std from the dataframe if not provided\n",
    "        self.latitude_mean = lat_mean if lat_mean is not None else np.mean(np.array(self.hf_dataset['Latitude']))\n",
    "        self.latitude_std = lat_std if lat_std is not None else np.std(np.array(self.hf_dataset['Latitude']))\n",
    "        self.longitude_mean = lon_mean if lon_mean is not None else np.mean(np.array(self.hf_dataset['Longitude']))\n",
    "        self.longitude_std = lon_std if lon_std is not None else np.std(np.array(self.hf_dataset['Longitude']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract data\n",
    "        example = self.hf_dataset[idx]\n",
    "\n",
    "        # Load and process the image\n",
    "        image = example['image']\n",
    "        latitude = example['Latitude']\n",
    "        longitude = example['Longitude']\n",
    "        # image = image.rotate(-90, expand=True)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Normalize GPS coordinates\n",
    "        latitude = (latitude - self.latitude_mean) / self.latitude_std\n",
    "        longitude = (longitude - self.longitude_mean) / self.longitude_std\n",
    "        gps_coords = torch.tensor([latitude, longitude], dtype=torch.float32)\n",
    "\n",
    "        return image, gps_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua-UFAGyaFvL"
   },
   "source": [
    "## Creating dataloaders and visualizing the data\n",
    "- Compute train mean and std\n",
    "- Create Train dataset and dataloader\n",
    "- Create Validation dataset and dataloader\n",
    "- Create Test dataset and dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4BkKWQMQ8Co"
   },
   "outputs": [],
   "source": [
    "# Define the Transformation of the Data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Random crop and resize to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(degrees=15),  # Random rotation between -15 and 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Optionally, you can create a separate transform for inference without augmentations\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the training dataset and dataloader\n",
    "train_dataset = GPSImageDataset(hf_dataset=dataset_train, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Retrieve normalization parameters from the training dataset\n",
    "lat_mean = train_dataset.latitude_mean\n",
    "lat_std = train_dataset.latitude_std\n",
    "lon_mean = train_dataset.longitude_mean\n",
    "lon_std = train_dataset.longitude_std\n",
    "\n",
    "# Create the validation dataset and dataloader using training mean and std\n",
    "val_dataset = GPSImageDataset(\n",
    "    hf_dataset=dataset_val,\n",
    "    transform=inference_transform,\n",
    "    lat_mean=lat_mean,\n",
    "    lat_std=lat_std,\n",
    "    lon_mean=lon_mean,\n",
    "    lon_std=lon_std\n",
    ")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Create the Test dataset and loader using training mean and std\n",
    "test_dataset = GPSImageDataset(\n",
    "    hf_dataset=dataset_test,\n",
    "    transform=inference_transform,\n",
    "    lat_mean=lat_mean,\n",
    "    lat_std=lat_std,\n",
    "    lon_mean=lon_mean,\n",
    "    lon_std=lon_std\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i028XRKnh6-v"
   },
   "outputs": [],
   "source": [
    "# Verify loading\n",
    "for images, gps_coords in train_dataloader:\n",
    "    print(images.size(), gps_coords.size())\n",
    "    break\n",
    "for images, gps_coords in val_dataloader:\n",
    "    print(images.size(), gps_coords.size())\n",
    "    break\n",
    "for images, gps_coords in test_dataloader:\n",
    "    print(images.size(), gps_coords.size())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkaQtacFiWK8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    tensor = tensor.numpy().transpose((1, 2, 0))  # Convert from C x H x W to H x W x C\n",
    "    tensor = std * tensor + mean  # Denormalize\n",
    "    tensor = np.clip(tensor, 0, 1)  # Clip to keep pixel values between 0 and 1\n",
    "    return tensor\n",
    "\n",
    "data_iter = iter(train_dataloader)\n",
    "images, gps_coords = next(data_iter)  # Get a batch of images and labels\n",
    "# Denormalize the first image in the batch for display\n",
    "itr = 0\n",
    "for im in images:\n",
    "  image = denormalize(im, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "  # Plot the image\n",
    "  plt.imshow(image)\n",
    "  plt.title(f'Latitude: {gps_coords[itr][0].item():.4f}, Longitude: {gps_coords[itr][1].item():.4f}')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  itr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYriL36vW3eM"
   },
   "source": [
    "# **DinoResNetModel Definition and Training Testing Loop**\n",
    "- The following section defines the Model, Training loop and testing loop.\n",
    "- The model is a fusion of ResNet-18 and uses Dino ViT for feature extractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fuN5Wp9pQp3"
   },
   "source": [
    "## Fine Tune Parameters\n",
    "- @todo Tune the parameters to lower the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIle5H75nolb"
   },
   "outputs": [],
   "source": [
    "# Parameter Configurations\n",
    "# You can also figure out other parameters to fine-tune\n",
    "cfg = {\n",
    "    \"train_bs\":32,\n",
    "    \"test_bs\":32,\n",
    "    \"val_bs\":32,\n",
    "    \"num_epochs\": 5,\n",
    "    \"lr\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_YSmdrs1GX"
   },
   "source": [
    "## DinoResNetModel Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtBHXyCJgO2r"
   },
   "outputs": [],
   "source": [
    "# Import all the dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoModel\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomDinoResNetModel(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, resnet_name=\"microsoft/resnet-50\", dino_name=\"facebook/dino-vits16\", num_classes=2):\n",
    "      super().__init__()\n",
    "\n",
    "      # Load pre-trained Dino model from Hugging Face\n",
    "      self.dino = AutoModel.from_pretrained(dino_name)\n",
    "\n",
    "      # Load pre-trained ResNet model from Hugging Face\n",
    "      self.resnet = AutoModelForImageClassification.from_pretrained(resnet_name)\n",
    "\n",
    "      # Access the Linear layer within the Sequential classifier\n",
    "      self.resnet_features = self.resnet.config.num_labels  # Number of output labels (ResNet logits)\n",
    "\n",
    "      # Freeze DINO layers (no gradient updates)\n",
    "      for param in self.dino.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "      # Get feature dimensions\n",
    "      self.dino_features = self.dino.config.hidden_size  # Typically 768 for DINO models\n",
    "      total_features = self.dino_features + self.resnet_features  # Combine DINO and ResNet features\n",
    "\n",
    "      # Create the fusion network to combine features\n",
    "      self.fusion = nn.Sequential(\n",
    "          nn.Linear(total_features, 1024),  # Match total_features\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3),\n",
    "          nn.Linear(1024, 512),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3),\n",
    "          nn.Linear(512, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.2),\n",
    "          nn.Linear(256, num_classes)\n",
    "      )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input size x: [batch_size, num_channels, 224, 224]\n",
    "        '''\n",
    "\n",
    "        # Get Dino features\n",
    "        dino_output = self.dino(x).last_hidden_state[:,0] # shape [batch_size, 768]\n",
    "\n",
    "        # Get ReNet Features\n",
    "        resnet_output = self.resnet.resnet(x)\n",
    "        resnet_features = self.resnet(images).logits\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((dino_output, resnet_features), dim=1) # Shape: [batch_size, 768 + resnet_features]\n",
    "\n",
    "\n",
    "        # Pass through the fusion network\n",
    "        output = self.fusion(combined_features) # shape [batch_size, 2]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        \"\"\"\n",
    "        Save model locally using the Hugging Face format.\n",
    "        save_path - Defined saving path\n",
    "        \"\"\"\n",
    "        self.save_pretrained(save_path)\n",
    "\n",
    "    def push_model(self, repo_name):\n",
    "        \"\"\"\n",
    "        Push the model to the Hugging Face Hub.\n",
    "        \"\"\"\n",
    "        self.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cMCbWR5hKgb"
   },
   "source": [
    "## Training and Validation Loop Definition\n",
    "- Below section defines the training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9WXBRBJlJ57"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from geopy.distance import geodesic\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomDinoResNetModel(\n",
    "    resnet_name=\"microsoft/resnet-50\",\n",
    "    dino_name=\"facebook/dino-vitb16\"\n",
    ")\n",
    "\n",
    "# Since DINO is frozen, we only need to train ResNet and fusion network parameters\n",
    "trainable_params = list(model.resnet.parameters()) + list(model.fusion.parameters())\n",
    "optimizer = torch.optim.Adam(trainable_params, lr=cfg[\"lr\"])\n",
    "\n",
    "# Add a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, gps_coords in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} / {num_epochs}\"):\n",
    "        images, gps_coords = images.to(device), gps_coords.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the fusion model\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, gps_coords)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    baseline_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, gps_coords in tqdm(val_dataloader, desc=f\"Validating Epoch {epoch + 1}\"):\n",
    "            # Moving all relevant data to GPU\n",
    "            images = images.to(device)\n",
    "            gps_coords = gps_coords.to(device)\n",
    "\n",
    "            batch_size = gps_coords.size(0)\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Model predictions\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Denormalize predictions and actual GPS coordinates\n",
    "            preds_denorm = outputs.cpu().numpy() * np.array([lat_std, lon_std]) + np.array([lat_mean, lon_mean])\n",
    "            actuals_denorm = gps_coords.cpu().numpy() * np.array([lat_std, lon_std]) + np.array([lat_mean, lon_mean])\n",
    "\n",
    "            # Compute geodesic distances between predictions and actuals\n",
    "            for pred, actual in zip(preds_denorm, actuals_denorm):\n",
    "                distance = geodesic((actual[0], actual[1]), (pred[0], pred[1])).meters\n",
    "                val_loss += distance ** 2  # Squared distance\n",
    "\n",
    "            # Baseline predictions (mean coordinates)\n",
    "            baseline_preds = np.array([lat_mean, lon_mean])\n",
    "\n",
    "            # Compute geodesic distances between baseline preds and actuals\n",
    "            for actual in actuals_denorm:\n",
    "                distance = geodesic((actual[0], actual[1]), (baseline_preds[0], baseline_preds[1])).meters\n",
    "                baseline_loss += distance ** 2  # Squared distance\n",
    "\n",
    "    # Compute average losses\n",
    "    val_loss /= total_samples\n",
    "    baseline_loss /= total_samples\n",
    "\n",
    "    # Compute RMSE\n",
    "    val_rmse = np.sqrt(val_loss)\n",
    "    baseline_rmse = np.sqrt(baseline_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss (meters^2): {val_loss:.2f}, Baseline Loss (meters^2): {baseline_loss:.2f}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation RMSE (meters): {val_rmse:.2f}, Baseline RMSE (meters): {baseline_rmse:.2f}\")\n",
    "\n",
    "print('Training complete')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'val_rmse': val_rmse,\n",
    "}, 'dino_resnet_gps_regressor.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdLEWIKhaX_o"
   },
   "source": [
    "## Testing the learnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AdRxPfkWy2n"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "# Initialize lists to store predictions and actual values\n",
    "all_preds = [] # Prediction values\n",
    "all_actuals = [] # Actual Values\n",
    "\n",
    "model.eval() # set the model to be in evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, gps_coords in tqdm(test_dataloader, desc = f\"Testing Progress\"):\n",
    "        images, gps_coords = images.to(device), gps_coords.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Denormalize predictions and actual values\n",
    "        preds = outputs.cpu() * torch.tensor([lat_std, lon_std]) + torch.tensor([lat_mean, lon_mean])\n",
    "        actuals = gps_coords.cpu() * torch.tensor([lat_std, lon_std]) + torch.tensor([lat_mean, lon_mean])\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_actuals.append(actuals)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_actuals = torch.cat(all_actuals).numpy()\n",
    "\n",
    "# Compute error metrics\n",
    "mae = mean_absolute_error(all_actuals, all_preds)\n",
    "rmse = mean_squared_error(all_actuals, all_preds, squared=False)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5dBFdULYk0v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieve normalization parameters from the training dataset\n",
    "lat_mean = train_dataset.latitude_mean\n",
    "lat_std = train_dataset.latitude_std\n",
    "lon_mean = train_dataset.longitude_mean\n",
    "lon_std = train_dataset.longitude_std\n",
    "\n",
    "# Denormalize predictions and actual values\n",
    "all_preds_denorm = all_preds * np.array([lat_std, lon_std]) + np.array([lat_mean, lon_mean])\n",
    "all_actuals_denorm = all_actuals * np.array([lat_std, lon_std]) + np.array([lat_mean, lon_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12BMgT0CXVu7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot actual points\n",
    "plt.scatter(all_actuals_denorm[:, 1], all_actuals_denorm[:, 0], label='Actual', color='blue', alpha=0.6)\n",
    "\n",
    "# Plot predicted points\n",
    "plt.scatter(all_preds_denorm[:, 1], all_preds_denorm[:, 0], label='Predicted', color='red', alpha=0.6)\n",
    "\n",
    "# Draw lines connecting actual and predicted points\n",
    "for i in range(len(all_actuals_denorm)):\n",
    "    plt.plot(\n",
    "        [all_actuals_denorm[i, 1], all_preds_denorm[i, 1]],\n",
    "        [all_actuals_denorm[i, 0], all_preds_denorm[i, 0]],\n",
    "        color='gray', linewidth=0.5\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Actual vs. Predicted GPS Coordinates with Error Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcG68M_4hqu4"
   },
   "source": [
    "# 1. *Pushing the Model to the Hugging Face(HF Model)*\n",
    "\n",
    "Use this code if you loaded model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyzw7E30hrw8"
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"cis519/dino_resnet_fusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPH15fyngNl7"
   },
   "source": [
    "You load this model by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqEp8OeygSgh"
   },
   "outputs": [],
   "source": [
    "model = CustomDinoResNetModel.from_pretrained(\"cis519/dino_resnet_fusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-nfMsIf0MHd"
   },
   "source": [
    "# 2. Pushing the model to the Hugging Face (Torchvision Model)\n",
    "\n",
    "Use this code if you loaded the model from Torchvision or built the model from scratch using PyTorch. If you built your model from scratch, make sure to follow the guidelines described here - https://huggingface.co/docs/hub/en/models-uploading#upload-a-pytorch-model-using-huggingfacehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1i22h251R-e"
   },
   "outputs": [],
   "source": [
    "path_name = \"resnet_gps_regressor_complete.pth\"\n",
    "model_save_path = \"/content/resnet_gps_regressor_complete.pth\"\n",
    "torch.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Pw_R-cF1ull"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, Repository\n",
    "\n",
    "# Initialize HfApi\n",
    "api = HfApi()\n",
    "\n",
    "# modify repo_name if necessary\n",
    "repo_name = \"dino_resnet_fusion\"\n",
    "organization_name = \"cis519\"\n",
    "repo_url = api.create_repo(repo_id=f\"{organization_name}/{repo_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9A6ADyb2pSy"
   },
   "outputs": [],
   "source": [
    "repo_local_dir = \"/content/ImageToGPSproject_dino_resnet_fusion\"\n",
    "repo = Repository(local_dir=repo_local_dir, clone_from=repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S4-AGNU3GIw"
   },
   "outputs": [],
   "source": [
    "os.rename(model_save_path, f\"{repo_local_dir}/resnet_gps_regressor_complete.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBc2Nrd5MbhN"
   },
   "outputs": [],
   "source": [
    "readme_content = f\"\"\"\n",
    "# Image to GPS Model: DINO-ResNet Fusion\n",
    "\n",
    "## Training Data Statistics\n",
    "The following mean and standard deviation values were used to normalize the GPS coordinates:\n",
    "\n",
    "- **Latitude Mean**: {lat_mean:.6f}\n",
    "- **Latitude Std**: {lat_std:.6f}\n",
    "- **Longitude Mean**: {lon_mean:.6f}\n",
    "- **Longitude Std**: {lon_std:.6f}\n",
    "\"\"\"\n",
    "readme_path = f\"{repo_local_dir}/README.md\"\n",
    "with open(readme_path, \"w\") as readme_file:\n",
    "    readme_file.write(readme_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83AQht153Moa"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"danielzhong2000@gmail.com\"\n",
    "!git config --global user.name \"DanioZhong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yF5ovcpG3STu"
   },
   "outputs": [],
   "source": [
    "repo.push_to_hub(commit_message=\"Add fine-tuned dino-ResNet50 model for Image to GPS project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFT5lm-1gtiF"
   },
   "source": [
    "You load this model by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgq3Z9zngu6K"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "# Specify the repository and the filename of the model you want to load\n",
    "repo_id = \"cis519/dino_resnet_fusion\"  # Replace with your repo name\n",
    "filename = \"resnet_gps_regressor_complete.pth\"\n",
    "\n",
    "model_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "\n",
    "# Load the model using torch\n",
    "model_test = torch.load(model_path)\n",
    "model_test.eval()  # Set the model to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cis5810-p7-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
